{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54c42615-2e2c-4904-8c64-3452156eb08e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "\n",
    "# Specify your target container, parent folder, and the \"raw\" folder\n",
    "container_name = \"publictransportdata\"\n",
    "parent_folder = \"public_transport_data\"\n",
    "folder_name = \"raw\"\n",
    "\n",
    "# Loop through the desired months (January to May)\n",
    "for month in range(1, 6):\n",
    "    # Generate data for the specified month\n",
    "    start_date = datetime(2023, month, 1)\n",
    "    if month == 5:\n",
    "        end_date = datetime(2023, 5, 31)  # May has 31 days\n",
    "    else:\n",
    "        end_date = datetime(2023, month + 1, 1) - timedelta(days=1)\n",
    "\n",
    "    date_generated = [start_date + timedelta(days=x) for x in range(0, (end_date-start_date).days + 1)]\n",
    "\n",
    "    transport_types = [\"Bus\", \"Train\", \"Tram\", \"Metro\"]\n",
    "    routes = [\"Route_\" + str(i) for i in range(1, 11)]\n",
    "    stations = [\"Station_\" + str(i) for i in range(1, 21)]\n",
    "\n",
    "    # Randomly select 5 days as extreme weather days\n",
    "    extreme_weather_days = random.sample(date_generated, 5)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for date in date_generated:\n",
    "        for _ in range(32):  # 32 records per day to get a total of 992 records per month\n",
    "            transport = random.choice(transport_types)\n",
    "            route = random.choice(routes)\n",
    "\n",
    "            # Normal operating hours\n",
    "            departure_hour = random.randint(5, 22)\n",
    "            departure_minute = random.randint(0, 59)\n",
    "\n",
    "            # Introducing Unusual Operating Hours for buses\n",
    "            if transport == \"Bus\" and random.random() < 0.05:  # 5% chance\n",
    "                departure_hour = 3\n",
    "\n",
    "            departure_time = f\"{departure_hour:02}:{departure_minute:02}\"\n",
    "\n",
    "            # Normal duration\n",
    "            duration = random.randint(10, 120)\n",
    "\n",
    "            # Introducing Short Turnarounds\n",
    "            if random.random() < 0.05:  # 5% chance\n",
    "                duration = random.randint(1, 5)\n",
    "\n",
    "            # General delay\n",
    "            delay = random.randint(0, 15)\n",
    "\n",
    "            # Weather Impact\n",
    "            if date in extreme_weather_days:\n",
    "                # Increase delay by 10 to 60 minutes\n",
    "                delay += random.randint(10, 60)\n",
    "\n",
    "                # 10% chance to change the route\n",
    "                if random.random() < 0.10:\n",
    "                    route = random.choice(routes)\n",
    "\n",
    "            total_minutes = departure_minute + duration + delay\n",
    "            arrival_hour = departure_hour + total_minutes // 60\n",
    "            arrival_minute = total_minutes % 60\n",
    "            arrival_time = f\"{arrival_hour:02}:{arrival_minute:02}\"\n",
    "\n",
    "            passengers = random.randint(1, 100)\n",
    "            departure_station = random.choice(stations)\n",
    "            arrival_station = random.choice(stations)\n",
    "\n",
    "            data.append([date, transport, route, departure_time, arrival_time, passengers, departure_station, arrival_station, delay])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"Date\", \"TransportType\", \"Route\", \"DepartureTime\", \"ArrivalTime\", \"Passengers\", \"DepartureStation\", \"ArrivalStation\", \"Delay\"])\n",
    "    \n",
    "    # Convert the pandas DataFrame to a PySpark DataFrame\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "\n",
    "    # Specify the path in Azure Data Lake Storage Gen2\n",
    "    data_path = f\"abfss://{container_name}@faissalmoufllastorage.dfs.core.windows.net/{parent_folder}/{folder_name}/public_transport_data_{month}.csv\"\n",
    "\n",
    "    # Write the PySpark DataFrame to the \"raw\" folder in ADLS Gen2 as a CSV file\n",
    "    spark_df.write.csv(data_path, mode=\"overwrite\", header=True, sep=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "public-transport",
   "widgets": {}
  },
  "colab": {
   "authorship_tag": "ABX9TyNEcAPisy+UgH2pdAMa2tgd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
